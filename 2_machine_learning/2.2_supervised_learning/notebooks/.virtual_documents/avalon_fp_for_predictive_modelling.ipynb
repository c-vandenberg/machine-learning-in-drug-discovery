

















import sys
import os
import time
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from IPython.display import display, HTML
#-------------------------------------------------------
from rdkit.Chem import AllChem
from rdkit import Chem
from rdkit.DataStructs.cDataStructs import ExplicitBitVect
from rdkit.Avalon import pyAvalonTools
from rdkit.Chem import PandasTools
from rdkit.Chem import rdMolDescriptors
from tqdm import tqdm
#-------------------------------------------------------
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import ShuffleSplit, cross_validate, train_test_split
#-------------------------------------------------------
from lightgbm import LGBMRegressor
from typing import List, Dict
#-------------------------------------------------------
os.environ['SUP_LEARN_PYTHON_DIR_PATH'] =  os.path.join(os.getcwd(), '../src')
os.environ['SUP_LEARN_DATA_DIR_PATH'] =  os.path.join(os.getcwd(), '../data')
sys.path.append(os.getenv('SUP_LEARN_PYTHON_DIR_PATH'))
sys.path.append(os.getenv('SUP_LEARN_DATA_DIR_PATH'))

from utils import avalon_fingerprints_utils








# Load data
homo_lumo_dataset: pd.DataFrame = pd.read_csv(
    os.path.join(
        os.getenv('SUP_LEARN_DATA_DIR_PATH'), 
        'raw/orbital-energies-input-data.csv'
    )
)

# Add 2D structure columnd
PandasTools.AddMoleculeColumnToFrame(
    homo_lumo_dataset,
    'SMILES',
    'Structure',
    includeFingerprints=True
)

# Generate Avalon fingerprints
homo_lumo_avalon_fpts: np.ndarray = avalon_fingerprints_utils.generate_avalon_fingerprints_from_mol(
    homo_lumo_dataset['Structure'],
    4096
)

# Insert into DataFrame. Each row represents a molecule's Avalon fingerprint and
# each column an individual bit
homo_lumo_ava_fpts_dataset: pd.DataFrame = pd.DataFrame(
    homo_lumo_avalon_fpts,
    columns=['Bit_{}'.format(bit) for bit in range(homo_lumo_avalon_fpts.shape[1])]
)

homo_lumo_ava_fpts_dataset.head()





# Instantiate the `LGBMRegressor` model. The `n_estimators` argument specifies the number of boosting
# iteratinos (i.e. the number of trees in the model). The `random_state` argument sets the seed for the
# random number generator, ensuring the results are reproducible (i.e. that the same random sequences are
# generated each time the code is run)
lgbm_regressor: LGBMRegressor = LGBMRegressor(n_estimators=800, random_state=42)





# Instantiate the `RandomForestRegressor`model. The `random_state` argument sets the seed for the random 
# number generator, ensuring the results are reproducible 
rf_regressor: RandomForestRegressor = RandomForestRegressor(random_state=42)





# Start timer to calculate total execution time
start_time: float = time.time()

# Create a cross-validator that randomly shuffles and splits data into training and test sets
# `n_splits=10` specifies that 10 splits should be created. This is the 10-fold cross-validation
# `test_size=0.3` specifies that 30% of the data should be used as the test set for each split
# `randdm_state=42` specifies the random seed to ensure reproducibility
homo_lumo_cross_validator: ShuffleSplit = ShuffleSplit(
    n_splits=10, 
    test_size=0.3, 
    random_state=42
)

# Define scoring metrics. 
# Metric `r2` is the coefficient of determination, which measures the proportion of variance explained by the model
# Metric `neg_mean_absolute_error` is the negative mean absolute error, measuring the average absolute errors
# between the predicted and actual values
homo_lumo_scoring_metrics: List[str] = ['r2', 'neg_mean_absolute_error']

# Cross-validation execution.
homo_lumo_cross_validation_scores: Dict = cross_validate(
    lgbm_regressor, # The LightGBM model to evaluate
    homo_lumo_ava_fpts_dataset, # The feature matrix
    homo_lumo_dataset.Energygap, # The target variable
    scoring=homo_lumo_scoring_metrics, # The list of metrics to evaluate
    cv=homo_lumo_cross_validator # The cross-validator
)

print(homo_lumo_cross_validation_scores)

end_time: float = time.time()
execution_time: float = end_time - start_time
print(
    '\n HOMO-LUMO Energy Gap Model Cross-Validation Execution Time: ', 
    round(execution_time/60, 2), 'min'
)


# Output coefficient of determination (R²) of LightGBM regressor 10-fold cross-validation
homo_lumo_cross_validation_scores['test_r2']


# Output mean absolute error (MAE) of LightGBM regressor 10-fold cross-validation 
# (negative of negative  mean absolute error)
-homo_lumo_cross_validation_scores['test_neg_mean_absolute_error']


# Output mean values of R² and MAE for 10-fold cross-validation of LightGBM regressor
print(
    'HOMO-LUMO Energy Gap Model Cross-Validation R²: ', 
    round(np.mean(homo_lumo_cross_validation_scores['test_r2']), 2), 
    '\n'
)

print(
    'HOMO-LUMO Energy Gap Model Cross-Validation Mean Absolute Error (MAE): ', 
    round(np.mean(-homo_lumo_cross_validation_scores['test_neg_mean_absolute_error']), 2)
)





# Split data into training and test sets using `train_test_split()` function
# `homo_lumo_model_x_train_data` and `homo_lumo_model_x_test_data` are the feature matrices 
# for training and testing (Avalon fingerprints)
# `homo_lumo_model_y_train_data` and `homo_lumo_model_y_test_data` are the target vectors for 
# training and testing (HOMO-LUMO energy gap)
(homo_lumo_model_x_train_data, homo_lumo_model_x_test_data, 
 homo_lumo_model_y_train_data, homo_lumo_model_y_test_data) = train_test_split(
    homo_lumo_ava_fpts_dataset, # The feature matrix (Avalon fingerprints)
    homo_lumo_dataset.Energygap, # The target variable (observed HOMO-LUMO energy gap)
    test_size=0.3, # 30% of the data is reserved for testing, and 70% is used for training
    random_state=42 # Random number generator seed
)

# LightGBM model training
ava_homo_lumo_lgbm_model: LGBMRegressor = lgbm_regressor.fit(
    homo_lumo_model_x_train_data, # Training feature matrix (Avalon fingerprints)
    homo_lumo_model_y_train_data # Training target vector (HOMO-LUMO energy gap)
)

# Test trained LightGBM model using testing feature matrix (Avalon fingerprints)
# Outputs a predicted target vector (predicted HOMO-LUMO energy gap)
homo_lumo_lgbm_model_predict: np.array = ava_homo_lumo_lgbm_model.predict(
    homo_lumo_model_x_test_data
)


# Measure model performance with Pearson correlation coefficient (R) between actual and predicted HOMO-LUMO gap values
# Slice correlation between predicted labels and actual labels from correlation matrix
homo_lumo_model_predict_r: np.float64 = np.corrcoef(
    homo_lumo_model_y_test_data, 
    homo_lumo_lgbm_model_predict
)[0, 1]

print(
    '\n LightGBM Regressor HOMO-LUMO Energy Gap Prediction R: ', 
    round(homo_lumo_model_predict_r, 2)
)


# Measure model performance with coefficient of determination (R²) score between actual and predicted HOMO-LUMO gap values
homo_lumo_model_predict_r2: float = r2_score(
    homo_lumo_model_y_test_data, 
    homo_lumo_lgbm_model_predict
)
print(
    '\n LightGBM Regressor HOMO-LUMO Energy Gap Prediction R²: ', 
    round(homo_lumo_model_predict_r2, 2)
)


# Measure model performance by calculating mean average error (MAE) between actual and predicted HOMO-LUMO gap values
homo_lumo_model_predict_mae: np.float64 = mean_absolute_error(
    homo_lumo_model_y_test_data, 
    homo_lumo_lgbm_model_predict
)

print(
    '\n LightGBM Regressor HOMO-LUMO Energy Gap Prediction MAE: ', 
    round(homo_lumo_model_predict_mae, 2)
)





# LightGBM Regressor HOMO-LUMO Energy Gap Prediction Parity Plot
sns.regplot(
    x=homo_lumo_lgbm_model_predict, 
    y=homo_lumo_model_y_test_data,
    line_kws={"lw":2,'ls':'--','color':'black',"alpha":0.7}
)
plt.xlabel(r"Predicted $\Delta E$ (kcal/mol) $\hat{y}$")
plt.ylabel(r"Observed $\Delta E$ (kcal/mol) $y$")
plt.title("Avalon Fingerprint HOMO-LUMO Energy Gap Prediction Parity Plot")
plt.grid(alpha=0.2)

homo_lumo_predict_label_text: str = (
    f"R = {homo_lumo_model_predict_r:.2f}\n"
    f"R² = {homo_lumo_model_predict_r2:.2f}\n"
    f"MAE (kcal/mol) = {homo_lumo_model_predict_mae:.2f}"
)

plt.text(0.05, 0.95, homo_lumo_predict_label_text, transform=plt.gca().transAxes, fontsize=10,
         verticalalignment='top', bbox=dict(facecolor='white', boxstyle='round,pad=0.5'))

plt.savefig(
    os.path.join(
        os.getenv('SUP_LEARN_DATA_DIR_PATH'),
        'analysis/plots/avalon-homo-lumo-energy-gap-parity-plot.png'
    )
)

plt.close()





























# Load data
buchwald_amin_yield_dataset: pd.DataFrame = pd.read_csv(
    os.path.join(
        os.getenv('SUP_LEARN_DATA_DIR_PATH'), 
        'raw/buchwald_yield_data.csv'
    )
)

# Output C-N cross-coupling reaction yields
buchwald_amin_yield_dataset.Output


# Calculate Avalon fingerprints for all four cross-coupling components
ligand_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    buchwald_amin_yield_dataset['Ligand'],
    2048
)

additive_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    buchwald_amin_yield_dataset['Additive'],
    1024
)

base_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    buchwald_amin_yield_dataset['Base'],
    1024
)

aryl_halide_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    buchwald_amin_yield_dataset['Aryl halide'],
    1024
)


# Concatenate Avalon fingerprints of the four cross-coupling components
# `axis=1` argument concatenates the arrays column-wise. This gives a new
# array where each row represents a molecule and each column represents a
# bit from one of the four fingerprint vectors
buchwald_amin_ava_fpts = np.concatenate(
    [
        ligand_ava_fpts,
        additive_ava_fpts,
        base_ava_fpts,
        aryl_halide_ava_fpts
    ],
    axis=1
)

# Insert into DataFrame. Each row represents a molecule's Avalon fingerprint and
# each column an individual bit
buchwald_amin_ava_fpts_dataset: pd.DataFrame = pd.DataFrame(
    buchwald_amin_ava_fpts,
    columns=['Col_A_{}'.format(bit + 1) for bit in range(buchwald_amin_ava_fpts.shape[1])]
)

buchwald_amin_ava_fpts_dataset





# Start timer to calculate total execution time
start_time: float = time.time()

# Create a cross-validator that randomly shuffles and splits data into training and test sets
# `n_splits=10` specifies that 10 splits should be created. This is the 10-fold cross-validation
# `test_size=0.3` specifies that 30% of the data should be used as the test set for each split
# `randdm_state=42` specifies the random seed to ensure reproducibility
cn_coupling_yields_cross_validator: ShuffleSplit = ShuffleSplit(
    n_splits=10, 
    test_size=0.3, 
    random_state=42
)

# Define scoring metrics. 
# Metric `r2` is the coefficient of determination, which measures the proportion of variance explained by the model
# Metric `neg_root_mean_squared_error` is the negative root mean squared error, a measure of the differences 
# between the predicted and actual values
cn_coupling_yields_scoring_metrics: List[str] = ['r2', 'neg_root_mean_squared_error']

# LightGBM regressor cross-validation execution.
cn_coupling_yields_cross_validation_scores: Dict = cross_validate(
    lgbm_regressor, # The LightGBM model to evaluate
    buchwald_amin_ava_fpts_dataset, # The feature matrix
    buchwald_amin_yield_dataset.Output, # The target variable (observed C-N cross-coupling yields)
    scoring=cn_coupling_yields_scoring_metrics, # The list of metrics to evaluate
    cv=cn_coupling_yields_cross_validator # The cross-validator
)

print(cn_coupling_yields_cross_validation_scores)

end_time: float = time.time()
execution_time: float = end_time - start_time
print(
    '\n C-N Cross-Coupling Model Cross-Validation Execution Time: ', 
    round(execution_time/60, 2), 'min'
)


# Output mean values of R² and MAE for 10-fold cross-validation of LightGBM regressor
print(
    'C-N Cross-Coupling Model Cross-Validation Cross-Validation R²: ', 
    round(np.mean(cn_coupling_yields_cross_validation_scores['test_r2']), 2), 
    '\n'
)

print(
    'C-N Cross-Coupling Model Cross-Validation Mean Absolute Error: ', 
    round(
        np.mean(-cn_coupling_yields_cross_validation_scores['test_neg_root_mean_squared_error']), 
        2
    )
)





# Split data into training and test sets using `train_test_split()` function
# `cn_coupling_avalon_fpts_x_train` and `cn_coupling_avalon_fpts_x_test` are the feature 
# matrices for training and testing (Avalon fingerprints).
# `cn_coupling_yields_y_train` and `cn_coupling_yields_y_test` are the target 
# vectors for training and testing (C-N cross-coupling yields)
(cn_coupling_avalon_fpts_x_train, cn_coupling_avalon_fpts_x_test, 
 cn_coupling_yields_y_train, cn_coupling_yields_y_test) = train_test_split(
    buchwald_amin_ava_fpts_dataset, # The feature matrix (Avalon fingerprints)
    buchwald_amin_yield_dataset.Output, # The target variable (observed C-N cross-coupling yield)
    test_size=0.3, # 30% of the data is reserved for testing, and 70% is used for training
    random_state=42 # Random number generator seed
)

# LightGBM model training
ava_cn_coupling_yields_lgbm_model: LGBMRegressor = lgbm_regressor.fit(
    cn_coupling_avalon_fpts_x_train, # Training feature matrix (Avalon fingerprints)
    cn_coupling_yields_y_train # Training target vector (C-N cross-coupling yields)
)

# Test trained LightGBM model using testing feature matrix (Avalon fingerprints)
# Outputs a predicted target vector (predicted C-N cross-coupling yields)
cn_coupling_yields_model_predict: np.array = ava_cn_coupling_yields_lgbm_model.predict(
    cn_coupling_avalon_fpts_x_test
)


# Measure model performance with Pearson correlation coefficient (R) between actual and predicted C-N cross-coupling yields
# Slice correlation between predicted labels and actual labels from correlation matrix
cn_coupling_yields_predict_r: np.float64 = np.corrcoef(
    cn_coupling_yields_y_test,
    cn_coupling_yields_model_predict
)[0, 1]

print(
    '\n LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction R: ', 
    round(cn_coupling_yields_predict_r, 2)
)


# Measure model performance with coefficient of determination (R²) score between actual and predicted C-N cross-coupling yields
cn_coupling_yields_predict_r2: float = r2_score(
    cn_coupling_yields_y_test,
    cn_coupling_yields_model_predict
)
print(
    '\n LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction R²: ', 
    round(cn_coupling_yields_predict_r2, 2)
)


# Measure model performance by calculating mean average error (MAE) between actual and predicted C-N cross-coupling yields
cn_coupling_yields_predict_mae: np.float64 = mean_absolute_error(
    cn_coupling_yields_y_test, 
    cn_coupling_yields_model_predict
)

print(
    '\n LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction MAE: ', 
    round(cn_coupling_yields_predict_mae, 2)
)


# LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction Parity Plot
sns.regplot(
    x=cn_coupling_yields_model_predict, 
    y=cn_coupling_yields_y_test,
    line_kws={"lw":2,'ls':'--','color':'black',"alpha":0.7}
)
plt.xlim(0, 100)
plt.ylim(0,100)
plt.xlabel(r"Predicted C-N Cross-Coupling Yield (%) $\hat{y}$")
plt.ylabel(r"Observed C-N Cross-Coupling Yield (%) $y$")
plt.title("Avalon Fingerprint C-N Cross-Coupling Yield Prediction Parity Plot")
plt.grid(alpha=0.2)

cn_coupling_yields_predict_label_text: str = (
    f"R = {cn_coupling_yields_predict_r:.2f}\n"
    f"R² = {cn_coupling_yields_predict_r2:.2f}\n"
    f"MAE (kcal/mol) = {cn_coupling_yields_predict_mae:.2f}"
)

plt.text(0.05, 0.95, cn_coupling_yields_predict_label_text, transform=plt.gca().transAxes, 
         fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', 
                                                         boxstyle='round,pad=0.5'))

plt.savefig(
    os.path.join(
        os.getenv('SUP_LEARN_DATA_DIR_PATH'),
        'analysis/plots/avalon-cn-couping-yield-parity-plot.png'
    )
)

plt.close()
































# Load data
ns_thiol_enantioselectivity_dataset: pd.DataFrame = pd.read_csv(
    os.path.join(
        os.getenv('SUP_LEARN_DATA_DIR_PATH'), 
        'raw/denmark_input_data.csv'
    )
)

# Output enantioselectivity (output column) for asymmetric N,S-acetal synthesis
ns_thiol_enantioselectivity_dataset.head()


# Calculate Avalon fingerprints for all catalysts, imines and thiols
cpa_catalyst_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    ns_thiol_enantioselectivity_dataset['Catalyst'],
    2048
)

imine_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    ns_thiol_enantioselectivity_dataset['Imine'],
    1024
)

thiol_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(
    ns_thiol_enantioselectivity_dataset['Thiol'],
    1024
)


# Concatenate Avalon fingerprints of the three N,S-Acetal synthesis reagents
# `axis=1` argument concatenates the arrays column-wise. This gives a new
# array where each row represents a molecule and each column represents a
# bit from one of the three fingerprint vectors
ns_thiol_synth_ava_fpts = np.concatenate(
    [
        cpa_catalyst_ava_fpts,
        imine_ava_fpts,
        thiol_ava_fpts
    ],
    axis=1
)

# Insert into DataFrame. Each row represents a reagents Avalon fingerprint and
# each column an individual bit
ns_thiol_synth_ava_fpts_dataset: pd.DataFrame = pd.DataFrame(
    ns_thiol_synth_ava_fpts,
    columns=['Col_A_{}'.format(bit + 1) for bit in range(ns_thiol_synth_ava_fpts.shape[1])]
)

ns_thiol_synth_ava_fpts_dataset





# Start timer to calculate total execution time
start_time: float = time.time()

# Create a cross-validator that randomly shuffles and splits data into training and test sets
# `n_splits=10` specifies that 10 splits should be created. This is the 10-fold cross-validation
# `test_size=0.441` specifies that 44.1% of the data should be used as the test set for each split
# `randdm_state=42` specifies the random seed to ensure reproducibility
ns_thiol_enantio_yield_cross_validator: ShuffleSplit = ShuffleSplit(
    n_splits=10, 
    test_size=0.441, 
    random_state=42
)

# Define scoring metrics. 
# Metric `r2` is the coefficient of determination, which measures the proportion of variance explained by the model
# Metric `neg_mean_absolute_error` is the negative mean absolute error, measuring the average absolute errors
# between the predicted and actual values
ns_thiol_enantio_yield_scoring_metrics: List[str] = ['r2', 'neg_mean_absolute_error']

# Random Forest regressor cross-validation execution.
ns_thiol_enantio_yield_cross_validation_scores: Dict = cross_validate(
    rf_regressor, # The Random Forest regressor model to evaluate
    ns_thiol_synth_ava_fpts_dataset, # The feature matrix
    ns_thiol_enantioselectivity_dataset.Output, # The target variable (observed asymmetric N,S-acetal synthesis enantioselectivity)
    scoring=ns_thiol_enantio_yield_scoring_metrics, # The list of metrics to evaluate
    cv=ns_thiol_enantio_yield_cross_validator # The cross-validator
)

print(ns_thiol_enantio_yield_cross_validation_scores)

end_time: float = time.time()
execution_time: float = end_time - start_time
print(
    '\n Asymmetric N,S-acetal Synthesis Model Cross-Validation Execution Time: ', 
    round(execution_time/60, 2), 'min'
)


# Output mean values of R² and MAE for 10-fold cross-validation of Random Forest regressor
print(
    'Asymmetric N,S-acetal Synthesis Model Cross-Validation Cross-Validation R²: ', 
    round(np.mean(ns_thiol_enantio_yield_cross_validation_scores['test_r2']), 3), 
    '\n'
)

print(
    'Asymmetric N,S-acetal Synthesis Model Cross-Validation Mean Absolute Error: ', 
    round(
        np.mean(-ns_thiol_enantio_yield_cross_validation_scores['test_neg_mean_absolute_error']), 
        3
    )
)





# Split data into training and test sets using `train_test_split()` function
# `ns_thiol_avalon_fpts_x_train` and `ns_thiol_avalon_fpts_x_test` are the feature 
# matrices for training and testing (Avalon fingerprints).
# `ns_thiol_enantio_y_train` and `ns_thiol_enantio_y_test` are the target 
# vectors for training and testing (N,S-thiol synthesis enantioselectivities)
(ns_thiol_avalon_fpts_x_train, ns_thiol_avalon_fpts_x_test, 
 ns_thiol_enantio_y_train, ns_thiol_enantio_y_test) = train_test_split(
    ns_thiol_synth_ava_fpts_dataset, # The feature matrix (Avalon fingerprints)
    ns_thiol_enantioselectivity_dataset.Output, # The target variable (observed N,S-thiol synthesis enantioselectivities)
    test_size=0.441, # 44.1% of the data is reserved for testing, and 65.9% is used for training
    random_state=42 # Random number generator seed
)

# Random Forest regressor model training
ns_thiol_enantio_rf_model: LGBMRegressor = rf_regressor.fit(
    ns_thiol_avalon_fpts_x_train, # Training feature matrix (Avalon fingerprints)
    ns_thiol_enantio_y_train # Training target vector (N,S-thiol synthesis enantioselectivities)
)

# Test trained Random Forest regressor model using testing feature matrix (Avalon fingerprints)
# Outputs a predicted target vector (predicted N,S-thiol synthesis enantioselectivities)
ns_thiol_enantio_rf_model_predict: np.array = ns_thiol_enantio_rf_model.predict(
    ns_thiol_avalon_fpts_x_test
)


# Measure model performance with Pearson correlation coefficient (R) between actual and predicted 
# N,S-thiol synthesis enantioselectivities
# Slice correlation between predicted labels and actual labels from correlation matrix
ns_thiol_enantio_predict_r: np.float64 = np.corrcoef(
    ns_thiol_enantio_y_test,
    ns_thiol_enantio_rf_model_predict
)[0, 1]

print(
    '\n Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction R: ', 
    round(ns_thiol_enantio_predict_r, 2)
)


# Measure model performance with coefficient of determination (R²) score between actual and predicted
# N,S-thiol synthesis enantioselectivities
ns_thiol_enantio_predict_r2: float = r2_score(
    ns_thiol_enantio_y_test,
    ns_thiol_enantio_rf_model_predict
)
print(
    '\n Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction R²: ', 
    round(ns_thiol_enantio_predict_r2, 2)
)


# Measure model performance by calculating mean average error (MAE) between actual and predicted
# N,S-thiol synthesis enantioselectivities
ns_thiol_enantio_predict_mae: np.float64 = mean_absolute_error(
    ns_thiol_enantio_y_test,
    ns_thiol_enantio_rf_model_predict
)

print(
    '\n Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction MAE: ', 
    round(ns_thiol_enantio_predict_mae, 3)
)


# Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction Parity Plot
sns.regplot(
    x=ns_thiol_enantio_rf_model_predict, 
    y=ns_thiol_enantio_y_test,
    line_kws={"lw":2,'ls':'--','color':'black',"alpha":0.7}
)
plt.xlabel(r"Predicted Enantioselectivities (kcal/mol) $\hat{y}$")
plt.ylabel(r"Observed Enantioselectivities (kcal/mol) $y$")
plt.title("Avalon Fingerprint N,S-thiol Synthesis Enantioselectivity Prediction Parity Plot", fontsize=10)
plt.grid(alpha=0.2)

ns_thiol_enantio_predict_label_text: str = (
    f"R = {ns_thiol_enantio_predict_r:.2f}\n"
    f"R² = {ns_thiol_enantio_predict_r2:.2f}\n"
    f"MAE (kcal/mol) = {ns_thiol_enantio_predict_mae:.2f}"
)

plt.text(0.05, 0.95, ns_thiol_enantio_predict_label_text, transform=plt.gca().transAxes, 
         fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', 
                                                         boxstyle='round,pad=0.5'))

plt.savefig(
    os.path.join(
        os.getenv('SUP_LEARN_DATA_DIR_PATH'),
        'analysis/plots/avalon-ns_thiol_enantio-parity-plot.png'
    )
)

plt.close()






