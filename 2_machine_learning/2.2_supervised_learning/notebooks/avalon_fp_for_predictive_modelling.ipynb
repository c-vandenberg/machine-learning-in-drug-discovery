{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7caa6fa-e462-40b9-b1f6-a006bfe2812a",
   "metadata": {},
   "source": [
    "# Avalon Fingerprints for Molecular Property and Reaction Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d312a4-cb55-47f1-8033-3c319256a01c",
   "metadata": {},
   "source": [
    "## 1. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa446599-2c6a-43ae-942f-bcd1eb8028c5",
   "metadata": {},
   "source": [
    "This notebook utilises **Avalon Fingerprints** to model and predict:\n",
    "1. **HOMO-LUMO Energy Gap of Organic Molecules**\n",
    "2. **Reaction Yield for Buchwald-Hartwig Amination (C-N Cross-Coupling) Reactions**\n",
    "3. **Catalytic Enantioselectivity of Thiol-Imine Reactions**\n",
    "\n",
    "The **supervised learning methods** we will use two algorithms for **regression**:\n",
    "1. **Random Forest Regressor**\n",
    "2. **LightGBM Regressors**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02ea8330-1c5d-423b-b496-afb097885429",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/avalon-fingerprints-predictive-model.jpg\", \n",
    "     alt=\"avalanon-fingerprints-predictive-model\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 1</b> Avalon Fingerprints for predictive modeling schematic. <b><sup>1</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf1709-8900-4a88-af31-8550b298f132",
   "metadata": {},
   "source": [
    "The dataset **<sup>2</sup>** we will use consists of molecular SMILES strings and HOMO-LUMO energy gap (meV) of around 2,900 small organic molecules. It is from the work by *Sandford et al.* **<sup>3</sup>**, which the work in this notebook is based on.\n",
    "\n",
    "In the work by *Sandfort et al.*, which utilises an **array of molecular fingerprints (multiple fingerprint features, MFF)**, as well as **individual molecular fingerprints (single fingerprint features, SFF)** to be used in **multivariate linear regression (MLR)** models to identify **linear free energy relationships** for **reaction prediction**.\n",
    "\n",
    "The fingerprints *Sandfort et al.* use include:\n",
    "* **Avalon Fingerprint** (3096 bits)\n",
    "* **Atom-Pairs Fingerprint** (3096 bits)\n",
    "* **Topological-Torsions Fingerprint** (3096 bits)\n",
    "* **MACCS-keys Fingerprint** (167 bits)\n",
    "* **RDKit Fingerprint**, radii 2, 4, 6, 8 (3096 bits)\n",
    "* **RDKit linear Fingerprint**, radii 2, 4, 6, 8 (3096 bits)\n",
    "* **RDKit layered Fingerprint**, radii 2, 4, 6, 8 (3096 bits)\n",
    "* **Morgan-Circular Fingerprint**, radii 0, 2, 4, 6 (3096 bits)\n",
    "* **Morgan-Circular Fingerprint with feature definitions**, radii 0, 2, 4, 6 (3096 bits)\n",
    "\n",
    "Interestingly, in the results and discussion, *Sandfort et al.* report that for the prediction of HOMO-LUMO energy gaps, the **Avalon fingerprint is the most suitable single fingerprint** for training the machine learning model. \n",
    "\n",
    "However for C-N cross-coupling reaction yield predictions and prediction of enantioselectivities, there was **no clear single most suitable fingerprint**. \n",
    "\n",
    "Therefore, the **MFF model was used exclusively for all studies in the paper**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d01126d0-24ae-4842-ba11-e486ee880156",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/sandfort-et-al-abstract.png\", \n",
    "     alt=\"sandfort-et-al-abstract-image\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 2</b> A structure-based platform for predicting chemical reactivity by <i>Sandfort et al.</i> <b><sup>3</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92aa43de-65a8-4bbc-a0ec-c4698087e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import display, HTML\n",
    "#-------------------------------------------------------\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.DataStructs.cDataStructs import ExplicitBitVect\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from tqdm import tqdm\n",
    "#-------------------------------------------------------\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import ShuffleSplit, cross_validate, train_test_split\n",
    "#-------------------------------------------------------\n",
    "from lightgbm import LGBMRegressor\n",
    "from typing import List, Dict\n",
    "#-------------------------------------------------------\n",
    "os.environ['SUP_LEARN_PYTHON_DIR_PATH'] =  os.path.join(os.getcwd(), '../src')\n",
    "os.environ['SUP_LEARN_DATA_DIR_PATH'] =  os.path.join(os.getcwd(), '../data')\n",
    "sys.path.append(os.getenv('SUP_LEARN_PYTHON_DIR_PATH'))\n",
    "sys.path.append(os.getenv('SUP_LEARN_DATA_DIR_PATH'))\n",
    "\n",
    "from utils import avalon_fingerprints_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d61d442-1df9-4224-b982-e75e325d3b61",
   "metadata": {},
   "source": [
    "# 2. Reactivity Prediction: HOMO-LUMO Energy Gap of Organic Molecules\n",
    "\n",
    "The HOMO-LUMO energy gap for the 2,900 small organic molecules in the dataset were obtained from **DFT calculations** (**Fig 3**). The small organic molecules in the dataset came from the *Sandfort et al.* group's inventory.\n",
    "\n",
    "Current machine learning models for the **quantitative modelling of reaction outcomes based on DFT-calculate descriptors** require molecules that have **at least one structural motif, atom or functional group in common**. **<sup>3</sup>**\n",
    "\n",
    "The goal of *Sandfort et al.* however, was to develop a model **applicable to a variety of organic chemical prediction problems**. HOMO-LUMO energy gap prediction is particularly useful in this context as it is a **property of the overall molecule**, and so a model trained on such data will represent and compare not only local substructures of a molecule, but also **global molecular characteristics**. **<sup>3</sup>**\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/sandfort-et-al-homo-lumo.png\", \n",
    "     alt=\"sandfort-et-al-homo-lumo\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 3</b> Calculated HOMO-LUMO energy gaps as an explicit molecular property by <i>Sandfort et al.</i> <b><sup>3</sup></b> (2-Fluoro-5-nitroaniline calculated HOMO-LUMO geometries shown).\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b29e7-0520-41c2-9da6-bba50fa22ed3",
   "metadata": {},
   "source": [
    "## 2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3b5ce7-bd56-4016-96c6-851cf26917cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 2904/2904 [00:00<00:00, 3207.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bit_0</th>\n",
       "      <th>Bit_1</th>\n",
       "      <th>Bit_2</th>\n",
       "      <th>Bit_3</th>\n",
       "      <th>Bit_4</th>\n",
       "      <th>Bit_5</th>\n",
       "      <th>Bit_6</th>\n",
       "      <th>Bit_7</th>\n",
       "      <th>Bit_8</th>\n",
       "      <th>Bit_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Bit_4086</th>\n",
       "      <th>Bit_4087</th>\n",
       "      <th>Bit_4088</th>\n",
       "      <th>Bit_4089</th>\n",
       "      <th>Bit_4090</th>\n",
       "      <th>Bit_4091</th>\n",
       "      <th>Bit_4092</th>\n",
       "      <th>Bit_4093</th>\n",
       "      <th>Bit_4094</th>\n",
       "      <th>Bit_4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bit_0  Bit_1  Bit_2  Bit_3  Bit_4  Bit_5  Bit_6  Bit_7  Bit_8  Bit_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "2      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   Bit_4086  Bit_4087  Bit_4088  Bit_4089  Bit_4090  Bit_4091  Bit_4092  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "\n",
       "   Bit_4093  Bit_4094  Bit_4095  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 4096 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "homo_lumo_dataset: pd.DataFrame = pd.read_csv(\n",
    "    os.path.join(\n",
    "        os.getenv('SUP_LEARN_DATA_DIR_PATH'), \n",
    "        'raw/orbital-energies-input-data.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add 2D structure columnd\n",
    "PandasTools.AddMoleculeColumnToFrame(\n",
    "    homo_lumo_dataset,\n",
    "    'SMILES',\n",
    "    'Structure',\n",
    "    includeFingerprints=True\n",
    ")\n",
    "\n",
    "# Generate Avalon fingerprints\n",
    "homo_lumo_avalon_fpts: np.ndarray = avalon_fingerprints_utils.generate_avalon_fingerprints_from_mol(\n",
    "    homo_lumo_dataset['Structure'],\n",
    "    4096\n",
    ")\n",
    "\n",
    "# Insert into DataFrame. Each row represents a molecule's Avalon fingerprint and\n",
    "# each column an individual bit\n",
    "homo_lumo_ava_fpts_dataset: pd.DataFrame = pd.DataFrame(\n",
    "    homo_lumo_avalon_fpts,\n",
    "    columns=['Bit_{}'.format(bit) for bit in range(homo_lumo_avalon_fpts.shape[1])]\n",
    ")\n",
    "\n",
    "homo_lumo_ava_fpts_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97038fd2-cc85-40f0-a8fa-e2318bf384dc",
   "metadata": {},
   "source": [
    "## 2.2 Instantiate and Train Models\n",
    "\n",
    "We will now **instantiate and train our models** on the Avalon fingerprint dataset.\n",
    "\n",
    "### 2.2.1 LightGBM Regressor (`LGBMRegressor`)\n",
    "\n",
    "LightGBM, which stands for **Light Gradient Boosting Machine**, is a **highly efficient and fast implementation of gradient boosting for decision tree algorithms**.\n",
    "* **Gradient Boosting** is a powerful machine learning technique used for **both regression and classification tasks**.\n",
    "* **It builds an ensemble of trees** in a **sequential manner**, where each new tree is **trained to correct the errors of the previous trees**.\n",
    "* This is in contrast to **bagging-based algorithms** such as **Random Forest**, where the trees in the ensemble are **built independently and combined**.\n",
    "* It **combines the predictions of multiple weaker learners** to create a **strong learner predictive model**.\n",
    "* Gradient boosting uses **gradient descent to minimise loss function loss** (*c.f.* `intro_to_supervised_learning.ipynb`). Each new tree is **fit on the negative gradient of the loss function** with respect to the **predictions of the previously built ensemble of trees**.\n",
    "\n",
    "LightGBM has the following key characteristics:\n",
    "1. **Speed and Efficiency**: LightGBM is **optimised for performance and memory usage**, making it **much faster than other gradient boosting implementations**.\n",
    "2. **Support for large datasets**: LightGBM can **handle large-scale data** with **millions of instances and features** efficiently.\n",
    "3. **Accuracy**: It provides **high accuracy** due to the implementation of advanced features like **leaf-wise tree growth** (uses the leaf with the **maximum reduction in loss to be split next**.\n",
    "\n",
    "The **`LGBMRegressor`** class in the **LightGBM library** is **designed specifically for regression tasks**. It inherits from LightGBM's core functionalities and allows for the building of **powerful regression models**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c969c3-f0ad-4b27-9b2b-d2cd6a7649fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the `LGBMRegressor` model. The `n_estimators` argument specifies the number of boosting\n",
    "# iteratinos (i.e. the number of trees in the model). The `random_state` argument sets the seed for the\n",
    "# random number generator, ensuring the results are reproducible (i.e. that the same random sequences are\n",
    "# generated each time the code is run)\n",
    "lgbm_regressor: LGBMRegressor = LGBMRegressor(n_estimators=800, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af6f72-1b64-449c-8bf5-762707d1f32c",
   "metadata": {},
   "source": [
    "### 2.2.2 Random Forest Regressor (`RandomForestRegressor`)\n",
    "\n",
    "The class `RandomForestRegressor` is a **popular ensemble supervised learning method** from the **scikit-learn library**. It is used for **regression tasks** and, like LightGBM regressor, **combines the predictions of multiple weaker learners** to create a **strong learner predictive model**.\n",
    "\n",
    "However, it differs from LightGBM regressor in that it utilises the technique called **bagging** where the **predictions of the individual trees are aggregated through averaging to give a final, stronger prediction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d19ecd89-d0dc-4ee7-8a35-f98d8be500a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the `RandomForestRegressor`model. The `random_state` argument sets the seed for the random \n",
    "# number generator, ensuring the results are reproducible \n",
    "rf_regressor: RandomForestRegressor = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3e725-7028-4b8d-9787-61feadc3b837",
   "metadata": {},
   "source": [
    "## 2.3 10-Fold Cross-Validation of LightGBM Regressor Model using Avalon Fingerprints & HOMO-LUMO Energy Gap Dataset\n",
    "\n",
    "**Cross-validation** is a statistical method used to **evaluate the performance of a machine learning model** by **paritioning the original dataset** into a training set to train the model and a test set to evaluate it. \n",
    "\n",
    "The cross-validation method we will use is `ShuffleSplit` which **randomly shuffles** the data before **splitting it into a specified number of splits**. In this case, we will split it 10 times, hence a **10-fold cross-validation**.\n",
    "\n",
    "Cross-validation provides a **more reliable esimate of model performance** than a **single train-test split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cf53a6-4579-4e4f-bfa0-01c6e5fe0003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2048\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 191.052642\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2062\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1031\n",
      "[LightGBM] [Info] Start training from score 190.942365\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2026\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1013\n",
      "[LightGBM] [Info] Start training from score 190.505767\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2086\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1043\n",
      "[LightGBM] [Info] Start training from score 190.301348\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2072\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1036\n",
      "[LightGBM] [Info] Start training from score 190.380834\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2010\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1005\n",
      "[LightGBM] [Info] Start training from score 190.861500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2064\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1032\n",
      "[LightGBM] [Info] Start training from score 189.935321\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2022\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1011\n",
      "[LightGBM] [Info] Start training from score 190.327045\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2002\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1001\n",
      "[LightGBM] [Info] Start training from score 191.145542\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1984\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 992\n",
      "[LightGBM] [Info] Start training from score 190.968234\n",
      "{'fit_time': array([0.87206674, 0.80334377, 0.71215916, 0.82542753, 0.82359171,\n",
      "       0.80954528, 0.7982688 , 0.79821539, 0.79751134, 0.79219294]), 'score_time': array([0.03551531, 0.03350687, 0.03254938, 0.03384447, 0.03356576,\n",
      "       0.03324962, 0.03351474, 0.03499508, 0.03347659, 0.03330541]), 'test_r2': array([0.91044654, 0.90800796, 0.91153183, 0.92018218, 0.9045963 ,\n",
      "       0.89865031, 0.90671041, 0.90788038, 0.89827042, 0.91485459]), 'test_neg_mean_absolute_error': array([-5.79133628, -5.82072238, -5.86919926, -5.52286442, -6.21463951,\n",
      "       -6.16613145, -5.97132058, -6.12992087, -5.94971449, -5.76417806])}\n",
      "\n",
      " HOMO-LUMO Energy Gap Model Cross-Validation Execution Time:  0.14 min\n"
     ]
    }
   ],
   "source": [
    "# Start timer to calculate total execution time\n",
    "start_time: float = time.time()\n",
    "\n",
    "# Create a cross-validator that randomly shuffles and splits data into training and test sets\n",
    "# `n_splits=10` specifies that 10 splits should be created. This is the 10-fold cross-validation\n",
    "# `test_size=0.3` specifies that 30% of the data should be used as the test set for each split\n",
    "# `randdm_state=42` specifies the random seed to ensure reproducibility\n",
    "homo_lumo_cross_validator: ShuffleSplit = ShuffleSplit(\n",
    "    n_splits=10, \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define scoring metrics. \n",
    "# Metric `r2` is the coefficient of determination, which measures the proportion of variance explained by the model\n",
    "# Metric `neg_mean_absolute_error` is the negative mean absolute error, measuring the average absolute errors\n",
    "# between the predicted and actual values\n",
    "homo_lumo_scoring_metrics: List[str] = ['r2', 'neg_mean_absolute_error']\n",
    "\n",
    "# Cross-validation execution.\n",
    "homo_lumo_cross_validation_scores: Dict = cross_validate(\n",
    "    lgbm_regressor, # The LightGBM model to evaluate\n",
    "    homo_lumo_ava_fpts_dataset, # The feature matrix\n",
    "    homo_lumo_dataset.Energygap, # The target variable\n",
    "    scoring=homo_lumo_scoring_metrics, # The list of metrics to evaluate\n",
    "    cv=homo_lumo_cross_validator # The cross-validator\n",
    ")\n",
    "\n",
    "print(homo_lumo_cross_validation_scores)\n",
    "\n",
    "end_time: float = time.time()\n",
    "execution_time: float = end_time - start_time\n",
    "print(\n",
    "    '\\n HOMO-LUMO Energy Gap Model Cross-Validation Execution Time: ', \n",
    "    round(execution_time/60, 2), 'min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1c4e59-ba68-4f51-8b3c-3ec06d0a4e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91044654, 0.90800796, 0.91153183, 0.92018218, 0.9045963 ,\n",
       "       0.89865031, 0.90671041, 0.90788038, 0.89827042, 0.91485459])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output coefficient of determination (R²) of LightGBM regressor 10-fold cross-validation\n",
    "homo_lumo_cross_validation_scores['test_r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e772cc89-7f58-4952-ae5d-8eccaa530694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.79133628, 5.82072238, 5.86919926, 5.52286442, 6.21463951,\n",
       "       6.16613145, 5.97132058, 6.12992087, 5.94971449, 5.76417806])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output mean absolute error (MAE) of LightGBM regressor 10-fold cross-validation \n",
    "# (negative of negative  mean absolute error)\n",
    "-homo_lumo_cross_validation_scores['test_neg_mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449331ed-81ba-4dba-99de-f6fedd353ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOMO-LUMO Energy Gap Model Cross-Validation R²:  0.91 \n",
      "\n",
      "HOMO-LUMO Energy Gap Model Cross-Validation Mean Absolute Error (MAE):  5.92\n"
     ]
    }
   ],
   "source": [
    "# Output mean values of R² and MAE for 10-fold cross-validation of LightGBM regressor\n",
    "print(\n",
    "    'HOMO-LUMO Energy Gap Model Cross-Validation R²: ', \n",
    "    round(np.mean(homo_lumo_cross_validation_scores['test_r2']), 2), \n",
    "    '\\n'\n",
    ")\n",
    "\n",
    "print(\n",
    "    'HOMO-LUMO Energy Gap Model Cross-Validation Mean Absolute Error (MAE): ', \n",
    "    round(np.mean(-homo_lumo_cross_validation_scores['test_neg_mean_absolute_error']), 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd719947-a7c3-4022-892c-1a95c850c609",
   "metadata": {},
   "source": [
    "## 2.4 Split Avalon Fingerprints and HOMO-LUMO Energy Gap Dataset Into Training Data & Testing Data to Train & Test LightGBM Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8168fc-ce6e-4a3a-a4ef-311676a1fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2048\n",
      "[LightGBM] [Info] Number of data points in the train set: 2032, number of used features: 1024\n",
      "[LightGBM] [Info] Start training from score 191.052642\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets using `train_test_split()` function\n",
    "# `homo_lumo_model_x_train_data` and `homo_lumo_model_x_test_data` are the feature matrices \n",
    "# for training and testing (Avalon fingerprints)\n",
    "# `homo_lumo_model_y_train_data` and `homo_lumo_model_y_test_data` are the target vectors for \n",
    "# training and testing (HOMO-LUMO energy gap)\n",
    "(homo_lumo_model_x_train_data, homo_lumo_model_x_test_data, \n",
    " homo_lumo_model_y_train_data, homo_lumo_model_y_test_data) = train_test_split(\n",
    "    homo_lumo_ava_fpts_dataset, # The feature matrix (Avalon fingerprints)\n",
    "    homo_lumo_dataset.Energygap, # The target variable (observed HOMO-LUMO energy gap)\n",
    "    test_size=0.3, # 30% of the data is reserved for testing, and 70% is used for training\n",
    "    random_state=42 # Random number generator seed\n",
    ")\n",
    "\n",
    "# LightGBM model training\n",
    "ava_homo_lumo_lgbm_model: LGBMRegressor = lgbm_regressor.fit(\n",
    "    homo_lumo_model_x_train_data, # Training feature matrix (Avalon fingerprints)\n",
    "    homo_lumo_model_y_train_data # Training target vector (HOMO-LUMO energy gap)\n",
    ")\n",
    "\n",
    "# Test trained LightGBM model using testing feature matrix (Avalon fingerprints)\n",
    "# Outputs a predicted target vector (predicted HOMO-LUMO energy gap)\n",
    "homo_lumo_lgbm_model_predict: np.array = ava_homo_lumo_lgbm_model.predict(\n",
    "    homo_lumo_model_x_test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be94b8b-bf16-42e4-9520-4cb709301a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LightGBM Regressor HOMO-LUMO Energy Gap Prediction R:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance with Pearson correlation coefficient (R) between actual and predicted HOMO-LUMO gap values\n",
    "# Slice correlation between predicted labels and actual labels from correlation matrix\n",
    "homo_lumo_model_predict_r: np.float64 = np.corrcoef(\n",
    "    homo_lumo_model_y_test_data, \n",
    "    homo_lumo_lgbm_model_predict\n",
    ")[0, 1]\n",
    "\n",
    "print(\n",
    "    '\\n LightGBM Regressor HOMO-LUMO Energy Gap Prediction R: ', \n",
    "    round(homo_lumo_model_predict_r, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fcba70-9241-438f-92e6-f40688239e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LightGBM Regressor HOMO-LUMO Energy Gap Prediction R²:  0.91\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance with coefficient of determination (R²) score between actual and predicted HOMO-LUMO gap values\n",
    "homo_lumo_model_predict_r2: float = r2_score(\n",
    "    homo_lumo_model_y_test_data, \n",
    "    homo_lumo_lgbm_model_predict\n",
    ")\n",
    "print(\n",
    "    '\\n LightGBM Regressor HOMO-LUMO Energy Gap Prediction R²: ', \n",
    "    round(homo_lumo_model_predict_r2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fa89e44-a22a-4186-a393-75db0124269d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LightGBM Regressor HOMO-LUMO Energy Gap Prediction MAE:  5.79\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance by calculating mean average error (MAE) between actual and predicted HOMO-LUMO gap values\n",
    "homo_lumo_model_predict_mae: np.float64 = mean_absolute_error(\n",
    "    homo_lumo_model_y_test_data, \n",
    "    homo_lumo_lgbm_model_predict\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\n LightGBM Regressor HOMO-LUMO Energy Gap Prediction MAE: ', \n",
    "    round(homo_lumo_model_predict_mae, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f58cb-06ec-4530-9c71-daaf4413ecb6",
   "metadata": {},
   "source": [
    "## 2.5 Parity Plot for Model HOMO-LUMO Energy Gapy Prediction From Avalon Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb446cf4-eea3-44cd-91bb-e35db9e96ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Regressor HOMO-LUMO Energy Gap Prediction Parity Plot\n",
    "sns.regplot(\n",
    "    x=homo_lumo_lgbm_model_predict, \n",
    "    y=homo_lumo_model_y_test_data,\n",
    "    line_kws={\"lw\":2,'ls':'--','color':'black',\"alpha\":0.7}\n",
    ")\n",
    "plt.xlabel(r\"Predicted $\\Delta E$ (kcal/mol) $\\hat{y}$\")\n",
    "plt.ylabel(r\"Observed $\\Delta E$ (kcal/mol) $y$\")\n",
    "plt.title(\"Avalon Fingerprint HOMO-LUMO Energy Gap Prediction Parity Plot\")\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "homo_lumo_predict_label_text: str = (\n",
    "    f\"R = {homo_lumo_model_predict_r:.2f}\\n\"\n",
    "    f\"R² = {homo_lumo_model_predict_r2:.2f}\\n\"\n",
    "    f\"MAE (kcal/mol) = {homo_lumo_model_predict_mae:.2f}\"\n",
    ")\n",
    "\n",
    "plt.text(0.05, 0.95, homo_lumo_predict_label_text, transform=plt.gca().transAxes, fontsize=10,\n",
    "         verticalalignment='top', bbox=dict(facecolor='white', boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        os.getenv('SUP_LEARN_DATA_DIR_PATH'),\n",
    "        'analysis/plots/avalon-homo-lumo-energy-gap-parity-plot.png'\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a608792-4dcc-4f71-a6f1-83230f9e4d3c",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../data/analysis/plots/avalon-homo-lumo-energy-gap-parity-plot.png\", \n",
    "     alt=\"avalon-fingerprints-homo-lumo-model-evaluation\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "        <b>Fig 4</b> Parity plot for LightGMB regressor HOMO-LUMO energy gap prediction from Avalon molecular fingerprints\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a75c01-af87-42cb-a3bb-9440df3d60d4",
   "metadata": {},
   "source": [
    "In **Fig 5**, we can see a comparison from the model performance evaluation in the paper by *Sandford et al.* **<sup>3</sup>** We are using the research group's inventory dataset. \n",
    "\n",
    "Although *Sandford et al.* is using an **MFF model** (i.e. more than one molecular fingerprint), the $R^2$ and mean absolute error of our cross-validation **is comparable to theirs**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48f4df54-0506-4cd8-97d1-1af3ec082851",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/sandfort-et-al-homo-lumo-performance-evaluation.jpg\", \n",
    "     alt=\"sandfort-mff-model-eval\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 5</b> Performance evaluation of the MFF model on the QM9 dataset and the research group's inventory dataset by <i>Sandfort et al.</i> <b><sup>3</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97523759-3e4d-4d2b-af6e-c70769009e1a",
   "metadata": {},
   "source": [
    "# 3. Reactivity Prediction: Buchwald-Hartwig Amination (C-N Cross-Coupling) Reaction Yield\n",
    "\n",
    "In comparison to **stereoselectivities/enantioselectivities**, the **quantitative prediction of yields** can be **more demanding** as they are **influenced by many parameters** and **do not rely on a single elementary step alone**. **<sup>3</sup>**\n",
    "\n",
    "In their paper, the *Sandford et al.* group cite the pioneering work of *Ahneman et al.* **<sup>4</sup>**  who were able to predict the reaction yields of C-N cross coupling reactions by using a dataset of more than 4,000 reactions. **<sup>3</sup>**\n",
    "\n",
    "*Ahneman et al.* collected the training data via **high-throughput experiementation** using **combinatorial synthesis of four reaction componenets**. \n",
    "\n",
    "The total number of reaction components was:\n",
    "* 15 aryl halides\n",
    "* 23 isoxazole additives\n",
    "* 4 ligands\n",
    "* 3 bases\n",
    "\n",
    "This brings the total number of reactions evaluated to **4140 ($15 \\times 3 \\times 23 \\times 4$)**.\n",
    "\n",
    "The high-throughput experimenation involved **three 1536 well plates**, with **each well accomodating one reaction**. This would allow for a total of **4608 simulataneous reactions ($3 \\times 1536$)**, with **yields determined via UPLC with di-*tert*-butyldiphenyl as an internal standard**.\n",
    "\n",
    "Not all of the evaluated reactions were used in the dataset. These included:\n",
    "1,. **Control reactions**.\n",
    "2. Reactions where the **isoxazole additive starting material overlapped with nearby peaks in UPLC**, making the **yield difficult to quanitify**.\n",
    "\n",
    "After these reactions had been removed, this brought the total number of reactions in the dataset to **3,960**. These were then used in the training of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b8557a2-7cd7-4c5a-aae7-5e5c62f72fff",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/ahneman-et-al-cn-coupling-components.png\", \n",
    "         alt=\"ahneman-cn-coupling-components\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "        <b>Fig 6</b> <i>Ahneman et al.</i> C-N cross-couping reaction components <b><sup>4</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15470401-e90b-4338-8f16-7a2f6c47cf47",
   "metadata": {},
   "source": [
    "For the **features of the models**, *Ahneman et al.* used **B3LYP/6-31G\\* DFT calculations** to **calculate the following descriptors**:\n",
    "* Electrostatic charge\n",
    "* NMR shift\n",
    "* Molecular volume\n",
    "* Surface area\n",
    "* Ovality\n",
    "* Molecular weight\n",
    "* $E_{HOMO}$\n",
    "* $E_{LUMO}$\n",
    "* Electronegativity\n",
    "* Hardness\n",
    "* Dipole moment\n",
    "\n",
    "In total, **120 descriptors were calculated** for the components of the C-N cross-coupling reactions:\n",
    "* Additive descriptors (19)\n",
    "* Aryl halide descriptors (27)\n",
    "* Base descriptors (10)\n",
    "* Ligand descriptors (64)\n",
    "\n",
    "The model training was carried out using these descriptors, with a 70/30 split of training and test data. Various machine learning algorithms were used, and their parity plots were compared (**Fig 7**)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32fa8fdd-458e-4714-8349-b12b81bfbedb",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/ahneman-et-al-model-evaluation.png\", \n",
    "     alt=\"ahneman-cn-coupling-model-evaluation\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "        <b>Fig 7</b> <i>Ahneman et al.</i> Parity plots for various machine learning algorithms for C-N cross-couping reaction yield prediction <b><sup>4</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe43aa-b97d-495f-8aba-bcfb164a0407",
   "metadata": {},
   "source": [
    "*Sandford et al.* used the dataset of *Ahneman et al.* to train and test both their MFF and SFF models for to compare their models performance against those in **Fig 6**.\n",
    "\n",
    "We will utilise this same dataset to implement a **LightGBM regressor model** with our **Avalon fingerprint descriptors**. We will then compare our model's prediction with that of *Ahneman et al.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85b866a-6755-44f0-9b39-4b32e9e80562",
   "metadata": {},
   "source": [
    "## 3.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51807646-3670-423b-8751-fe125b63aa66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       70.410458\n",
       "1       11.064457\n",
       "2       10.223550\n",
       "3       20.083383\n",
       "4        0.492663\n",
       "          ...    \n",
       "3950     4.344677\n",
       "3951    47.156275\n",
       "3952     0.701552\n",
       "3953    15.561565\n",
       "3954    73.739939\n",
       "Name: Output, Length: 3955, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "buchwald_amin_yield_dataset: pd.DataFrame = pd.read_csv(\n",
    "    os.path.join(\n",
    "        os.getenv('SUP_LEARN_DATA_DIR_PATH'), \n",
    "        'raw/buchwald_yield_data.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Output C-N cross-coupling reaction yields\n",
    "buchwald_amin_yield_dataset.Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dff6b54-2a5e-4d75-87d6-9a780fc7299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 3955/3955 [00:06<00:00, 635.77it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 3955/3955 [00:00<00:00, 4623.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 3955/3955 [00:01<00:00, 3286.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 3955/3955 [00:00<00:00, 6658.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Avalon fingerprints for all four cross-coupling components\n",
    "ligand_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    buchwald_amin_yield_dataset['Ligand'],\n",
    "    2048\n",
    ")\n",
    "\n",
    "additive_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    buchwald_amin_yield_dataset['Additive'],\n",
    "    1024\n",
    ")\n",
    "\n",
    "base_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    buchwald_amin_yield_dataset['Base'],\n",
    "    1024\n",
    ")\n",
    "\n",
    "aryl_halide_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    buchwald_amin_yield_dataset['Aryl halide'],\n",
    "    1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a32fe3e-6766-42f0-aa9b-1fabdbfbcafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_A_1</th>\n",
       "      <th>Col_A_2</th>\n",
       "      <th>Col_A_3</th>\n",
       "      <th>Col_A_4</th>\n",
       "      <th>Col_A_5</th>\n",
       "      <th>Col_A_6</th>\n",
       "      <th>Col_A_7</th>\n",
       "      <th>Col_A_8</th>\n",
       "      <th>Col_A_9</th>\n",
       "      <th>Col_A_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col_A_5111</th>\n",
       "      <th>Col_A_5112</th>\n",
       "      <th>Col_A_5113</th>\n",
       "      <th>Col_A_5114</th>\n",
       "      <th>Col_A_5115</th>\n",
       "      <th>Col_A_5116</th>\n",
       "      <th>Col_A_5117</th>\n",
       "      <th>Col_A_5118</th>\n",
       "      <th>Col_A_5119</th>\n",
       "      <th>Col_A_5120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3955 rows × 5120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Col_A_1  Col_A_2  Col_A_3  Col_A_4  Col_A_5  Col_A_6  Col_A_7  Col_A_8  \\\n",
       "0           0        0        0        0        0        0        0        0   \n",
       "1           0        0        0        0        0        0        0        0   \n",
       "2           0        0        0        0        0        0        0        0   \n",
       "3           0        0        0        0        0        0        0        0   \n",
       "4           0        0        0        0        0        0        0        0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3950        0        0        0        0        0        0        0        0   \n",
       "3951        0        0        0        0        0        0        0        0   \n",
       "3952        0        0        0        0        0        0        0        0   \n",
       "3953        0        0        0        0        0        0        0        0   \n",
       "3954        0        0        0        0        0        0        0        0   \n",
       "\n",
       "      Col_A_9  Col_A_10  ...  Col_A_5111  Col_A_5112  Col_A_5113  Col_A_5114  \\\n",
       "0           0         0  ...           0           0           0           0   \n",
       "1           0         0  ...           0           0           0           1   \n",
       "2           0         0  ...           0           0           0           0   \n",
       "3           0         0  ...           0           0           0           0   \n",
       "4           0         0  ...           0           0           0           0   \n",
       "...       ...       ...  ...         ...         ...         ...         ...   \n",
       "3950        0         0  ...           0           0           0           1   \n",
       "3951        0         0  ...           0           0           0           1   \n",
       "3952        0         0  ...           0           0           0           0   \n",
       "3953        0         0  ...           0           0           0           0   \n",
       "3954        0         0  ...           0           0           0           0   \n",
       "\n",
       "      Col_A_5115  Col_A_5116  Col_A_5117  Col_A_5118  Col_A_5119  Col_A_5120  \n",
       "0              0           0           0           0           0           0  \n",
       "1              0           0           0           0           0           0  \n",
       "2              0           0           1           0           0           0  \n",
       "3              0           0           1           0           0           0  \n",
       "4              0           0           0           0           0           0  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "3950           0           0           0           0           0           0  \n",
       "3951           0           0           0           0           0           0  \n",
       "3952           0           0           1           0           0           0  \n",
       "3953           0           0           1           0           0           0  \n",
       "3954           0           0           1           0           0           0  \n",
       "\n",
       "[3955 rows x 5120 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate Avalon fingerprints of the four cross-coupling components\n",
    "# `axis=1` argument concatenates the arrays column-wise. This gives a new\n",
    "# array where each row represents a molecule and each column represents a\n",
    "# bit from one of the four fingerprint vectors\n",
    "buchwald_amin_ava_fpts = np.concatenate(\n",
    "    [\n",
    "        ligand_ava_fpts,\n",
    "        additive_ava_fpts,\n",
    "        base_ava_fpts,\n",
    "        aryl_halide_ava_fpts\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Insert into DataFrame. Each row represents a molecule's Avalon fingerprint and\n",
    "# each column an individual bit\n",
    "buchwald_amin_ava_fpts_dataset: pd.DataFrame = pd.DataFrame(\n",
    "    buchwald_amin_ava_fpts,\n",
    "    columns=['Col_A_{}'.format(bit + 1) for bit in range(buchwald_amin_ava_fpts.shape[1])]\n",
    ")\n",
    "\n",
    "buchwald_amin_ava_fpts_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb06fa3-4158-45ad-a765-afaff07f9a16",
   "metadata": {},
   "source": [
    "## 3.2 10-Fold Cross-Validation of LightGBM Regressor Model using Avalon Fingerprints of Buchwald-Hartwig Cross-Coupling Components and Cross-Coupling Yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9827bb28-e8d8-4f92-a010-1ed065c9925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.142928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.110559\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.109879\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.016715\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.422986\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.042175\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.096357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.449105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.070164\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 32.997498\n",
      "{'fit_time': array([1.4633832 , 1.30970478, 1.35341358, 1.25208616, 1.61539793,\n",
      "       1.80150151, 1.7978487 , 1.95086265, 1.70004678, 1.58043623]), 'score_time': array([0.0501895 , 0.08201051, 0.11562324, 0.04744005, 0.1851697 ,\n",
      "       0.17644429, 0.20039988, 0.16720939, 0.16567898, 0.05095887]), 'test_r2': array([0.9539233 , 0.94593933, 0.94569323, 0.95567864, 0.9544228 ,\n",
      "       0.95253277, 0.94532573, 0.95206717, 0.94722408, 0.94938093]), 'test_neg_root_mean_squared_error': array([-5.9129151 , -6.33379851, -6.39298916, -5.82638655, -5.79140752,\n",
      "       -5.83864496, -6.17738341, -5.9729341 , -6.19285072, -6.13078845])}\n",
      "\n",
      " C-N Cross-Coupling Model Cross-Validation Execution Time:  0.29 min\n"
     ]
    }
   ],
   "source": [
    "# Start timer to calculate total execution time\n",
    "start_time: float = time.time()\n",
    "\n",
    "# Create a cross-validator that randomly shuffles and splits data into training and test sets\n",
    "# `n_splits=10` specifies that 10 splits should be created. This is the 10-fold cross-validation\n",
    "# `test_size=0.3` specifies that 30% of the data should be used as the test set for each split\n",
    "# `randdm_state=42` specifies the random seed to ensure reproducibility\n",
    "cn_coupling_yields_cross_validator: ShuffleSplit = ShuffleSplit(\n",
    "    n_splits=10, \n",
    "    test_size=0.3, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define scoring metrics. \n",
    "# Metric `r2` is the coefficient of determination, which measures the proportion of variance explained by the model\n",
    "# Metric `neg_root_mean_squared_error` is the negative root mean squared error, a measure of the differences \n",
    "# between the predicted and actual values\n",
    "cn_coupling_yields_scoring_metrics: List[str] = ['r2', 'neg_root_mean_squared_error']\n",
    "\n",
    "# LightGBM regressor cross-validation execution.\n",
    "cn_coupling_yields_cross_validation_scores: Dict = cross_validate(\n",
    "    lgbm_regressor, # The LightGBM model to evaluate\n",
    "    buchwald_amin_ava_fpts_dataset, # The feature matrix\n",
    "    buchwald_amin_yield_dataset.Output, # The target variable (observed C-N cross-coupling yields)\n",
    "    scoring=cn_coupling_yields_scoring_metrics, # The list of metrics to evaluate\n",
    "    cv=cn_coupling_yields_cross_validator # The cross-validator\n",
    ")\n",
    "\n",
    "print(cn_coupling_yields_cross_validation_scores)\n",
    "\n",
    "end_time: float = time.time()\n",
    "execution_time: float = end_time - start_time\n",
    "print(\n",
    "    '\\n C-N Cross-Coupling Model Cross-Validation Execution Time: ', \n",
    "    round(execution_time/60, 2), 'min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f58fd805-cab6-41c8-9e4e-e10efa5692ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-N Cross-Coupling Model Cross-Validation Cross-Validation R²:  0.95 \n",
      "\n",
      "C-N Cross-Coupling Model Cross-Validation Mean Absolute Error:  6.06\n"
     ]
    }
   ],
   "source": [
    "# Output mean values of R² and MAE for 10-fold cross-validation of LightGBM regressor\n",
    "print(\n",
    "    'C-N Cross-Coupling Model Cross-Validation Cross-Validation R²: ', \n",
    "    round(np.mean(cn_coupling_yields_cross_validation_scores['test_r2']), 2), \n",
    "    '\\n'\n",
    ")\n",
    "\n",
    "print(\n",
    "    'C-N Cross-Coupling Model Cross-Validation Mean Absolute Error: ', \n",
    "    round(\n",
    "        np.mean(-cn_coupling_yields_cross_validation_scores['test_neg_root_mean_squared_error']), \n",
    "        2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1320d-b46a-4c1e-a009-e508afebb7ee",
   "metadata": {},
   "source": [
    "## 3.3 Split Avalon Fingerprints and Cross-Coupling Yield Dataset Into Training Data & Testing Data to Train & Test LightGBM Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e237e9-621c-4b8b-b017-4664af4767dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1808\n",
      "[LightGBM] [Info] Number of data points in the train set: 2768, number of used features: 904\n",
      "[LightGBM] [Info] Start training from score 33.142928\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and test sets using `train_test_split()` function\n",
    "# `cn_coupling_avalon_fpts_x_train` and `cn_coupling_avalon_fpts_x_test` are the feature \n",
    "# matrices for training and testing (Avalon fingerprints).\n",
    "# `cn_coupling_yields_y_train` and `cn_coupling_yields_y_test` are the target \n",
    "# vectors for training and testing (C-N cross-coupling yields)\n",
    "(cn_coupling_avalon_fpts_x_train, cn_coupling_avalon_fpts_x_test, \n",
    " cn_coupling_yields_y_train, cn_coupling_yields_y_test) = train_test_split(\n",
    "    buchwald_amin_ava_fpts_dataset, # The feature matrix (Avalon fingerprints)\n",
    "    buchwald_amin_yield_dataset.Output, # The target variable (observed C-N cross-coupling yield)\n",
    "    test_size=0.3, # 30% of the data is reserved for testing, and 70% is used for training\n",
    "    random_state=42 # Random number generator seed\n",
    ")\n",
    "\n",
    "# LightGBM model training\n",
    "ava_cn_coupling_yields_lgbm_model: LGBMRegressor = lgbm_regressor.fit(\n",
    "    cn_coupling_avalon_fpts_x_train, # Training feature matrix (Avalon fingerprints)\n",
    "    cn_coupling_yields_y_train # Training target vector (C-N cross-coupling yields)\n",
    ")\n",
    "\n",
    "# Test trained LightGBM model using testing feature matrix (Avalon fingerprints)\n",
    "# Outputs a predicted target vector (predicted C-N cross-coupling yields)\n",
    "cn_coupling_yields_model_predict: np.array = ava_cn_coupling_yields_lgbm_model.predict(\n",
    "    cn_coupling_avalon_fpts_x_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9084f425-bcc8-4f8e-bccb-9a6aa0788c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction R:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance with Pearson correlation coefficient (R) between actual and predicted C-N cross-coupling yields\n",
    "# Slice correlation between predicted labels and actual labels from correlation matrix\n",
    "cn_coupling_yields_predict_r: np.float64 = np.corrcoef(\n",
    "    cn_coupling_yields_y_test,\n",
    "    cn_coupling_yields_model_predict\n",
    ")[0, 1]\n",
    "\n",
    "print(\n",
    "    '\\n LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction R: ', \n",
    "    round(cn_coupling_yields_predict_r, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8e6a86-4c11-4f4b-b137-9409fac2a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction R²:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance with coefficient of determination (R²) score between actual and predicted C-N cross-coupling yields\n",
    "cn_coupling_yields_predict_r2: float = r2_score(\n",
    "    cn_coupling_yields_y_test,\n",
    "    cn_coupling_yields_model_predict\n",
    ")\n",
    "print(\n",
    "    '\\n LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction R²: ', \n",
    "    round(cn_coupling_yields_predict_r2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cfadcfe-cd48-4773-95ac-0f31dbe9da81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction MAE:  4.11\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance by calculating mean average error (MAE) between actual and predicted C-N cross-coupling yields\n",
    "cn_coupling_yields_predict_mae: np.float64 = mean_absolute_error(\n",
    "    cn_coupling_yields_y_test, \n",
    "    cn_coupling_yields_model_predict\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\n LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction MAE: ', \n",
    "    round(cn_coupling_yields_predict_mae, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e9082e1-105c-4680-9cb0-ffc88f261d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Regressor C-N Cross-Coupling Reaction Yield Prediction Parity Plot\n",
    "sns.regplot(\n",
    "    x=cn_coupling_yields_model_predict, \n",
    "    y=cn_coupling_yields_y_test,\n",
    "    line_kws={\"lw\":2,'ls':'--','color':'black',\"alpha\":0.7}\n",
    ")\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(r\"Predicted C-N Cross-Coupling Yield (%) $\\hat{y}$\")\n",
    "plt.ylabel(r\"Observed C-N Cross-Coupling Yield (%) $y$\")\n",
    "plt.title(\"Avalon Fingerprint C-N Cross-Coupling Yield Prediction Parity Plot\")\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "cn_coupling_yields_predict_label_text: str = (\n",
    "    f\"R = {cn_coupling_yields_predict_r:.2f}\\n\"\n",
    "    f\"R² = {cn_coupling_yields_predict_r2:.2f}\\n\"\n",
    "    f\"MAE (kcal/mol) = {cn_coupling_yields_predict_mae:.2f}\"\n",
    ")\n",
    "\n",
    "plt.text(0.05, 0.95, cn_coupling_yields_predict_label_text, transform=plt.gca().transAxes, \n",
    "         fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', \n",
    "                                                         boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        os.getenv('SUP_LEARN_DATA_DIR_PATH'),\n",
    "        'analysis/plots/avalon-cn-couping-yield-parity-plot.png'\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a6e3a98-1941-47fe-b0c3-1bf9b27f2e77",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../data/analysis/plots/avalon-cn-couping-yield-parity-plot.png\", \n",
    "     alt=\"avalon-fingerprints-cn-coupling-model-evaluation\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "        <b>Fig 8</b> Parity plot for LightGMB regressor C-N cross-coupling yield prediction from Avalon fingerprints\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4140b-f81d-4ae7-b53e-6b1cb8d041bf",
   "metadata": {},
   "source": [
    "In **Fig 9**, we can see a performance evaluation comparison of the MFF model by *Sandford et al.* **<sup>3</sup>** and the Random Forest model by *Ahneman et al.* (labelled as *Doyle*) **<sup>4</sup>**. Both models used a random 70/30 split of the *Ahneman et al.* dataset.\n",
    "\n",
    "Our LightGBM regressor model cross-validation has a comparable $R^2$ and root mean squared error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bf514fd-d999-4e71-bae9-05b4d82addf9",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/sandfort-cn-coupling-performance-evaluation.JPG\", \n",
    "     alt=\"sandfort-cn-coupling-model-evaluation\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 9</b> Performance evaluation of the <i>Sandford et al.</i> MFF model on predicting C-N cross-coupling reaction yields. <b><sup>3</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62a806-8c97-4e0a-a297-6a695dd800a6",
   "metadata": {},
   "source": [
    "# 4. Reactivity Prediction: Catalytic Enantioselectivity of Thiol-Imine Reactions\n",
    "\n",
    "The **prediction of stereoselectivities/enantioselectivities in asymmetric catalysis** has been of great interest to the field of chemistry and has been the **focus of many multivariate linear regression models**. **<sup>3</sup>** **<sup>5</sup>** **<sup>6</sup>**\n",
    "\n",
    "In their paper, the *Sandford et al.* group cite the work of *Zahrt et al.*, **<sup>7</sup>** who report a machine learning-based approach for the prediction of **chiral phosphoric acid-catalysed thiol addition to *N*-acylimines**.\n",
    "\n",
    "For this **asymmetric *N,S*-acetal formation model reaction**, the training set included **combinatorial variations** of:\n",
    "* 43 chrial phosphoric acid (CPA) catalysts\n",
    "* 5 *N*-acyl imines\n",
    "* 5 thiols\n",
    "\n",
    "This brings the total number of reactions evaluated to **1,075 ($43 \\times 5 \\times 5$)**. To represent the CPA catalysts, a **steric-based molecular descriptor** called the **average steric occupancy (ASO)** was calculated. This ASO descriptor was based on **DFT-computed 3D representations of the entire conformer ensemble for each CPA catalyst**.\n",
    "\n",
    "The protocol for **generating these CPA catalyst ASO descriptors** is illustrated in **Fig 8**. This included:\n",
    "1. A **conformer distribution** for each CPA catalyst in the *in silico* library was obtained.\n",
    "2. For each catalyst, the conformers were **aligned and individually placed on identical grids**.\n",
    "3. If a given **grid point** on the grid was within the **van der Waals radius of an atom**, it was given a value of $1$; else, it was assigned a value of $0$.\n",
    "4. This process was repeated for *n* conformers, and upon completion each grid point had a **cumulative value ranging from 0 to *n***.\n",
    "5. These were then **normalised** by **dividing by *n***, such that **all grid points had a value between 0 and 1**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cc93e4f-22b5-4c24-b19e-bc155461099e",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/zahrt-et-al-aso-descriptors-generation.png\", \n",
    "     alt=\"zahrt-et-al-aso-descriptors-generation\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 10</b> <i>Zahrt et al.</i> <b>Generation of ASO descriptors</b>. <b>(A)</b> Pictorial description of ASO calculation. <b>(B)</b> ASO grid points occupied by no catalyst conformer atoms have values of 0 (red). Grid points occupied by atoms of all conformers have a value of 1 (blue). Flexible substituents lie between 0 and 1 (green and yellow regions). <b>(C)</b> ASO discrimination of 3,3′-substituent groups: ortho-substituted arenes\n",
    "(red), fused-ring substituents (blue), 3,5-disubstituted arenes (yellow), and\n",
    "all other groups (green). <b>(D)</b> Bar graph representation of ASO descriptors for two different types of Brønsted acid catalysts (CPA catalysts) <b><sup>7</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d7efa-fad2-4dc8-8944-891b1fd97f65",
   "metadata": {},
   "source": [
    "*Zahrt et al.* also derived **electronic descriptors** from the **perturbation that the CPA catalysts' substituents exerted on the electrostatic potential map of a quaternary ammonium ion**.\n",
    "\n",
    "These **substituent-based electronic descriptors** were then used in combination with the ASO descriptors to train the machine learning model to **predict enantioselectivity**. In total, this amounted to **16,384 features per catalyst**. \n",
    "\n",
    "Enantioselectivity was measured using **$\\Delta \\Delta G$ in kcal/mol**:\n",
    "* $\\Delta G$ is the **change in Gibbs free energy for a process or reaction**\n",
    "* $\\Delta \\Delta G$ refers to the **difference of in the $\\Delta G$ of two competing processes or reactions**, often used to describe the **selectivity or preference between two pathways**.\n",
    "\n",
    "In the context of chiral catalyst enantioselectivity, a **negative $\\Delta \\Delta G$** would indicate that **one enantiomer is preferentially formed**, with a **positive $\\Delta \\Delta G$** indicating that the **other enantiomer is preferentially formed**. For example:\n",
    "\n",
    "$$ \\Delta \\Delta G = \\Delta G_B - \\Delta G_A$$\n",
    "\n",
    "if:\n",
    "* $\\Delta G_A = -10 kcal/mol$\n",
    "* $\\Delta G_A = -12 kcal/mol$\n",
    "\n",
    "Then:\n",
    "$$ \\Delta \\Delta G = -12 - (-10) = -2 kcal/mol$$\n",
    "\n",
    "The negative $\\Delta \\Delta G$ value suggests that the **formation of enantiomer B is energetically more favourable than the formation of enantiomer A** by **2 kcal/mol**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95181997-5b36-4098-ad72-778345f64b65",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/zahrt-et-al-model-reaction.png\", \n",
    "     alt=\"zahrt-et-al-model-reaction\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 11</b> The enantioselective formation of <i>N,S</i>-acetals developed by <i>Antila et al.</i> <b><sup>8</sup></b> chosen by <i>Zahrt et al.</i> to evaluate the training set. <b><sup>7</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ca322-9e61-45ba-9273-560613d5981b",
   "metadata": {},
   "source": [
    "To **validate the ASO and electronic descriptors**, as well as the **training set selection protocol**, the training set was evaluated on a **previously optimised reaction** developed by *Antila et al.*; the **enantioselective formation of *N,S*-acetals** (**Fig 9**). It was chosen as it is **high yielding**, **highly reproducible** and can be **performed under ait at room temperature**, thus **facilitating rapid screening**. **<sup>3</sup>**\n",
    "\n",
    "*Zahrt et al.* found that a **distance-based support vector machine (SVM) algorithm** performed best with a **random 600/475 split of training data and test data**. This gave an **MAE = 0.152 kcal/mol**, averaged over **ten random dataset splits/divisions**.\n",
    "\n",
    "When comparing their MFF model to the model of *Zahrt et al.* with a **similar random splitting of the dataset**, *Sandfort et al.* found that **their model performed with slightly higher accuracy by using a random forest algorithm**. This gave an **MAE = 0.144 kcal/mol**, averaged over **ten random dataset splits/divisions**.\n",
    "\n",
    "Regarding the **division of the dataset**, both *Zahrt et al.*  and *Sandfort et al.* divided the data into:\n",
    "1. A **common training set**\n",
    "2. A **test set for substrates (sub)**\n",
    "3. A **test set for catalysts (cat)**\n",
    "4. A **test set for both substrates & catalysts (sub-cat)**\n",
    "\n",
    "We will utilise this same dataset with the same data split protocol to implement a **Random Forest regressor model** with our **Avalon fingerprint descriptors**. We will then compare our model's prediction with that of *Zahrt et al.* and *Sandfort et al.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f1612f9-6428-4f0a-a22b-8de2a7b021d9",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../reports/figures/sandfort-et-al-prediction-of-enantioselectivity.png\", \n",
    "     alt=\"enantioselective-model-reaction-summary\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "      <b>Fig 12</b> Simplified reaction scheme for the enantioselective formation of <i>N,S</i>-acetals developed by <i>Antila et al.</i> <b><sup>3</sup></b> <b><sup>8</sup></b>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833f70e-43a4-47c1-b513-6d139d55680f",
   "metadata": {},
   "source": [
    "## 4.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cdb0f37-e846-432d-844f-ad3af077ecde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Catalyst</th>\n",
       "      <th>Imine</th>\n",
       "      <th>Thiol</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...</td>\n",
       "      <td>O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2</td>\n",
       "      <td>SC1=CC=CC=C1</td>\n",
       "      <td>1.179891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...</td>\n",
       "      <td>O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2</td>\n",
       "      <td>CCS</td>\n",
       "      <td>0.501759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...</td>\n",
       "      <td>O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2</td>\n",
       "      <td>SC1CCCCC1</td>\n",
       "      <td>0.650584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...</td>\n",
       "      <td>O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2</td>\n",
       "      <td>SC1=CC=C(OC)C=C1</td>\n",
       "      <td>1.238109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...</td>\n",
       "      <td>O=C(C1=CC=CC=C1)/N=C/C2=CC=C(C(F)(F)F)C=C2</td>\n",
       "      <td>SC1=CC=CC=C1</td>\n",
       "      <td>1.179891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Catalyst  \\\n",
       "0  O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...   \n",
       "1  O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...   \n",
       "2  O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...   \n",
       "3  O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...   \n",
       "4  O=P1(O)OC2=C(C3=CC=CC=C3)C=C4C(C=CC=C4)=C2C5=C...   \n",
       "\n",
       "                                        Imine             Thiol    Output  \n",
       "0            O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2      SC1=CC=CC=C1  1.179891  \n",
       "1            O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2               CCS  0.501759  \n",
       "2            O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2         SC1CCCCC1  0.650584  \n",
       "3            O=C(C1=CC=CC=C1)/N=C/C2=CC=CC=C2  SC1=CC=C(OC)C=C1  1.238109  \n",
       "4  O=C(C1=CC=CC=C1)/N=C/C2=CC=C(C(F)(F)F)C=C2      SC1=CC=CC=C1  1.179891  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "ns_thiol_enantioselectivity_dataset: pd.DataFrame = pd.read_csv(\n",
    "    os.path.join(\n",
    "        os.getenv('SUP_LEARN_DATA_DIR_PATH'), \n",
    "        'raw/denmark_input_data.csv'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Output enantioselectivity (output column) for asymmetric N,S-acetal synthesis\n",
    "ns_thiol_enantioselectivity_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9dd48ed-65f3-496c-be52-107d386cc821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 1075/1075 [00:02<00:00, 425.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1075/1075 [00:00<00:00, 3289.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1075/1075 [00:00<00:00, 7622.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate Avalon fingerprints for all catalysts, imines and thiols\n",
    "cpa_catalyst_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    ns_thiol_enantioselectivity_dataset['Catalyst'],\n",
    "    2048\n",
    ")\n",
    "\n",
    "imine_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    ns_thiol_enantioselectivity_dataset['Imine'],\n",
    "    1024\n",
    ")\n",
    "\n",
    "thiol_ava_fpts: ExplicitBitVect = avalon_fingerprints_utils.generate_avalon_fingerprints_from_smiles(\n",
    "    ns_thiol_enantioselectivity_dataset['Thiol'],\n",
    "    1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a3a7323-68b6-4ffb-b2dc-35b58d2b6a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_A_1</th>\n",
       "      <th>Col_A_2</th>\n",
       "      <th>Col_A_3</th>\n",
       "      <th>Col_A_4</th>\n",
       "      <th>Col_A_5</th>\n",
       "      <th>Col_A_6</th>\n",
       "      <th>Col_A_7</th>\n",
       "      <th>Col_A_8</th>\n",
       "      <th>Col_A_9</th>\n",
       "      <th>Col_A_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Col_A_4087</th>\n",
       "      <th>Col_A_4088</th>\n",
       "      <th>Col_A_4089</th>\n",
       "      <th>Col_A_4090</th>\n",
       "      <th>Col_A_4091</th>\n",
       "      <th>Col_A_4092</th>\n",
       "      <th>Col_A_4093</th>\n",
       "      <th>Col_A_4094</th>\n",
       "      <th>Col_A_4095</th>\n",
       "      <th>Col_A_4096</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075 rows × 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Col_A_1  Col_A_2  Col_A_3  Col_A_4  Col_A_5  Col_A_6  Col_A_7  Col_A_8  \\\n",
       "0           0        0        0        0        0        0        0        0   \n",
       "1           0        0        0        0        0        0        0        0   \n",
       "2           0        0        0        0        0        0        0        0   \n",
       "3           0        0        0        0        0        0        0        0   \n",
       "4           0        0        0        0        0        0        0        0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1070        0        0        0        0        0        0        0        0   \n",
       "1071        0        0        0        0        0        0        0        0   \n",
       "1072        0        0        0        0        0        0        0        0   \n",
       "1073        0        0        0        0        0        0        0        0   \n",
       "1074        0        0        0        0        0        0        0        0   \n",
       "\n",
       "      Col_A_9  Col_A_10  ...  Col_A_4087  Col_A_4088  Col_A_4089  Col_A_4090  \\\n",
       "0           0         0  ...           0           0           0           0   \n",
       "1           0         0  ...           0           0           0           0   \n",
       "2           0         0  ...           0           0           0           0   \n",
       "3           0         0  ...           0           0           0           0   \n",
       "4           0         0  ...           0           0           0           0   \n",
       "...       ...       ...  ...         ...         ...         ...         ...   \n",
       "1070        0         0  ...           0           0           0           0   \n",
       "1071        0         0  ...           0           0           0           0   \n",
       "1072        0         0  ...           0           0           0           0   \n",
       "1073        0         0  ...           0           0           0           0   \n",
       "1074        0         0  ...           0           0           0           0   \n",
       "\n",
       "      Col_A_4091  Col_A_4092  Col_A_4093  Col_A_4094  Col_A_4095  Col_A_4096  \n",
       "0              0           0           0           0           0           0  \n",
       "1              0           0           0           0           0           0  \n",
       "2              0           0           0           0           0           0  \n",
       "3              0           0           0           0           0           0  \n",
       "4              0           0           0           0           0           0  \n",
       "...          ...         ...         ...         ...         ...         ...  \n",
       "1070           0           0           0           0           0           0  \n",
       "1071           0           0           0           0           0           0  \n",
       "1072           0           0           0           0           0           0  \n",
       "1073           0           0           0           0           0           0  \n",
       "1074           0           0           0           0           0           0  \n",
       "\n",
       "[1075 rows x 4096 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate Avalon fingerprints of the three N,S-Acetal synthesis reagents\n",
    "# `axis=1` argument concatenates the arrays column-wise. This gives a new\n",
    "# array where each row represents a molecule and each column represents a\n",
    "# bit from one of the three fingerprint vectors\n",
    "ns_thiol_synth_ava_fpts = np.concatenate(\n",
    "    [\n",
    "        cpa_catalyst_ava_fpts,\n",
    "        imine_ava_fpts,\n",
    "        thiol_ava_fpts\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Insert into DataFrame. Each row represents a reagents Avalon fingerprint and\n",
    "# each column an individual bit\n",
    "ns_thiol_synth_ava_fpts_dataset: pd.DataFrame = pd.DataFrame(\n",
    "    ns_thiol_synth_ava_fpts,\n",
    "    columns=['Col_A_{}'.format(bit + 1) for bit in range(ns_thiol_synth_ava_fpts.shape[1])]\n",
    ")\n",
    "\n",
    "ns_thiol_synth_ava_fpts_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6959550-cc77-4070-b588-b9227fd9a9ba",
   "metadata": {},
   "source": [
    "## 4.2 10-Fold Cross-Validation of Random Forest Regressor Model using Avalon Fingerprints of Asymmetric N,S-Acetal Synthesis Reagents and Enantioselectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8ef4848-4e1e-4ecc-b086-4a43721d07a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([2.18374705, 2.13135624, 2.07304835, 2.06848431, 2.06183887,\n",
      "       2.0545733 , 2.04501843, 2.12066364, 2.05288625, 2.04671192]), 'score_time': array([0.02414131, 0.02306151, 0.02347517, 0.02531052, 0.02295184,\n",
      "       0.02301526, 0.02479339, 0.02297664, 0.02405667, 0.02326322]), 'test_r2': array([0.90705316, 0.91493223, 0.91442174, 0.90377117, 0.89953987,\n",
      "       0.90361321, 0.89020908, 0.89501053, 0.89632396, 0.91219771]), 'test_neg_mean_absolute_error': array([-0.14157402, -0.13957821, -0.14215863, -0.14813604, -0.15217813,\n",
      "       -0.13714181, -0.14863539, -0.1487419 , -0.15457277, -0.14704008])}\n",
      "\n",
      " Asymmetric N,S-acetal Synthesis Model Cross-Validation Execution Time:  0.35 min\n"
     ]
    }
   ],
   "source": [
    "# Start timer to calculate total execution time\n",
    "start_time: float = time.time()\n",
    "\n",
    "# Create a cross-validator that randomly shuffles and splits data into training and test sets\n",
    "# `n_splits=10` specifies that 10 splits should be created. This is the 10-fold cross-validation\n",
    "# `test_size=0.441` specifies that 44.1% of the data should be used as the test set for each split\n",
    "# `randdm_state=42` specifies the random seed to ensure reproducibility\n",
    "ns_thiol_enantio_yield_cross_validator: ShuffleSplit = ShuffleSplit(\n",
    "    n_splits=10, \n",
    "    test_size=0.441, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define scoring metrics. \n",
    "# Metric `r2` is the coefficient of determination, which measures the proportion of variance explained by the model\n",
    "# Metric `neg_mean_absolute_error` is the negative mean absolute error, measuring the average absolute errors\n",
    "# between the predicted and actual values\n",
    "ns_thiol_enantio_yield_scoring_metrics: List[str] = ['r2', 'neg_mean_absolute_error']\n",
    "\n",
    "# Random Forest regressor cross-validation execution.\n",
    "ns_thiol_enantio_yield_cross_validation_scores: Dict = cross_validate(\n",
    "    rf_regressor, # The Random Forest regressor model to evaluate\n",
    "    ns_thiol_synth_ava_fpts_dataset, # The feature matrix\n",
    "    ns_thiol_enantioselectivity_dataset.Output, # The target variable (observed asymmetric N,S-acetal synthesis enantioselectivity)\n",
    "    scoring=ns_thiol_enantio_yield_scoring_metrics, # The list of metrics to evaluate\n",
    "    cv=ns_thiol_enantio_yield_cross_validator # The cross-validator\n",
    ")\n",
    "\n",
    "print(ns_thiol_enantio_yield_cross_validation_scores)\n",
    "\n",
    "end_time: float = time.time()\n",
    "execution_time: float = end_time - start_time\n",
    "print(\n",
    "    '\\n Asymmetric N,S-acetal Synthesis Model Cross-Validation Execution Time: ', \n",
    "    round(execution_time/60, 2), 'min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ba136a8-f962-4ae9-92ff-52048b612a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asymmetric N,S-acetal Synthesis Model Cross-Validation Cross-Validation R²:  0.904 \n",
      "\n",
      "Asymmetric N,S-acetal Synthesis Model Cross-Validation Mean Absolute Error:  0.146\n"
     ]
    }
   ],
   "source": [
    "# Output mean values of R² and MAE for 10-fold cross-validation of Random Forest regressor\n",
    "print(\n",
    "    'Asymmetric N,S-acetal Synthesis Model Cross-Validation Cross-Validation R²: ', \n",
    "    round(np.mean(ns_thiol_enantio_yield_cross_validation_scores['test_r2']), 3), \n",
    "    '\\n'\n",
    ")\n",
    "\n",
    "print(\n",
    "    'Asymmetric N,S-acetal Synthesis Model Cross-Validation Mean Absolute Error: ', \n",
    "    round(\n",
    "        np.mean(-ns_thiol_enantio_yield_cross_validation_scores['test_neg_mean_absolute_error']), \n",
    "        3\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7491e62-9945-4f2e-a748-7d83a55d9ba1",
   "metadata": {},
   "source": [
    "## 4.3 Split Avalon Fingerprints and Enantioselective Yield Dataset Into Training Data & Testing Data to Train & Test Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7147032-da04-4627-8f05-419e9d119c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets using `train_test_split()` function\n",
    "# `ns_thiol_avalon_fpts_x_train` and `ns_thiol_avalon_fpts_x_test` are the feature \n",
    "# matrices for training and testing (Avalon fingerprints).\n",
    "# `ns_thiol_enantio_y_train` and `ns_thiol_enantio_y_test` are the target \n",
    "# vectors for training and testing (N,S-thiol synthesis enantioselectivities)\n",
    "(ns_thiol_avalon_fpts_x_train, ns_thiol_avalon_fpts_x_test, \n",
    " ns_thiol_enantio_y_train, ns_thiol_enantio_y_test) = train_test_split(\n",
    "    ns_thiol_synth_ava_fpts_dataset, # The feature matrix (Avalon fingerprints)\n",
    "    ns_thiol_enantioselectivity_dataset.Output, # The target variable (observed N,S-thiol synthesis enantioselectivities)\n",
    "    test_size=0.441, # 44.1% of the data is reserved for testing, and 65.9% is used for training\n",
    "    random_state=42 # Random number generator seed\n",
    ")\n",
    "\n",
    "# Random Forest regressor model training\n",
    "ns_thiol_enantio_rf_model: LGBMRegressor = rf_regressor.fit(\n",
    "    ns_thiol_avalon_fpts_x_train, # Training feature matrix (Avalon fingerprints)\n",
    "    ns_thiol_enantio_y_train # Training target vector (N,S-thiol synthesis enantioselectivities)\n",
    ")\n",
    "\n",
    "# Test trained Random Forest regressor model using testing feature matrix (Avalon fingerprints)\n",
    "# Outputs a predicted target vector (predicted N,S-thiol synthesis enantioselectivities)\n",
    "ns_thiol_enantio_rf_model_predict: np.array = ns_thiol_enantio_rf_model.predict(\n",
    "    ns_thiol_avalon_fpts_x_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36a6da1d-153e-43f3-ba53-715d19c6187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction R:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance with Pearson correlation coefficient (R) between actual and predicted \n",
    "# N,S-thiol synthesis enantioselectivities\n",
    "# Slice correlation between predicted labels and actual labels from correlation matrix\n",
    "ns_thiol_enantio_predict_r: np.float64 = np.corrcoef(\n",
    "    ns_thiol_enantio_y_test,\n",
    "    ns_thiol_enantio_rf_model_predict\n",
    ")[0, 1]\n",
    "\n",
    "print(\n",
    "    '\\n Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction R: ', \n",
    "    round(ns_thiol_enantio_predict_r, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2702b558-9ccd-48ad-b08e-d521510babef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction R²:  0.91\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance with coefficient of determination (R²) score between actual and predicted\n",
    "# N,S-thiol synthesis enantioselectivities\n",
    "ns_thiol_enantio_predict_r2: float = r2_score(\n",
    "    ns_thiol_enantio_y_test,\n",
    "    ns_thiol_enantio_rf_model_predict\n",
    ")\n",
    "print(\n",
    "    '\\n Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction R²: ', \n",
    "    round(ns_thiol_enantio_predict_r2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "462a9959-a3fa-4420-9044-af3b376542c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction MAE:  0.142\n"
     ]
    }
   ],
   "source": [
    "# Measure model performance by calculating mean average error (MAE) between actual and predicted\n",
    "# N,S-thiol synthesis enantioselectivities\n",
    "ns_thiol_enantio_predict_mae: np.float64 = mean_absolute_error(\n",
    "    ns_thiol_enantio_y_test,\n",
    "    ns_thiol_enantio_rf_model_predict\n",
    ")\n",
    "\n",
    "print(\n",
    "    '\\n Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction MAE: ', \n",
    "    round(ns_thiol_enantio_predict_mae, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0311712d-0e01-4107-b251-1886fd7f9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor N,S-thiol Synthesis Enantioselectivities Prediction Parity Plot\n",
    "sns.regplot(\n",
    "    x=ns_thiol_enantio_rf_model_predict, \n",
    "    y=ns_thiol_enantio_y_test,\n",
    "    line_kws={\"lw\":2,'ls':'--','color':'black',\"alpha\":0.7}\n",
    ")\n",
    "plt.xlabel(r\"Predicted Enantioselectivities (kcal/mol) $\\hat{y}$\")\n",
    "plt.ylabel(r\"Observed Enantioselectivities (kcal/mol) $y$\")\n",
    "plt.title(\"Avalon Fingerprint N,S-thiol Synthesis Enantioselectivity Prediction Parity Plot\", fontsize=10)\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "ns_thiol_enantio_predict_label_text: str = (\n",
    "    f\"R = {ns_thiol_enantio_predict_r:.2f}\\n\"\n",
    "    f\"R² = {ns_thiol_enantio_predict_r2:.2f}\\n\"\n",
    "    f\"MAE (kcal/mol) = {ns_thiol_enantio_predict_mae:.2f}\"\n",
    ")\n",
    "\n",
    "plt.text(0.05, 0.95, ns_thiol_enantio_predict_label_text, transform=plt.gca().transAxes, \n",
    "         fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', \n",
    "                                                         boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        os.getenv('SUP_LEARN_DATA_DIR_PATH'),\n",
    "        'analysis/plots/avalon-ns_thiol_enantio-parity-plot.png'\n",
    "    )\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e90fc3-f421-4ced-8918-c86efdc55508",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../data/analysis/plots/avalon-ns_thiol_enantio-parity-plot.png\",\n",
    "     alt=\"avalon-fingerprints-asymm-ns-thio-synth-model-evaluation\"/>\n",
    "    <p style=\"text-align: center;\">\n",
    "        <b>Fig 13</b> Parity plot for Random Forest regressor N,S-thiol Synthesis Enantioselectivity prediction from Avalon fingerprints\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bfa0a6-666f-4c19-89d8-d75960f326cd",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "\n",
    "**[1]** Goshu, G.M. (2023) Avalon-fingerprints-for-machine-learning/avalon fingerprints for predictive modeling.ipynb at main · GASHAWMG/Avalon-fingerprints-for-machine-learning, *GitHub*. Available at: https://github.com/gashawmg/Avalon-fingerprints-for-machine-learning/blob/main/Avalon%20fingerprints%20for%20predictive%20modeling.ipynb (Accessed: 10 July 2024).<br><br>\n",
    "**[2]** Kühnemund, M. (2020) Marius Kühnemund / FP-DM-tool · GitLab, *GitLab*. Available at: https://zivgitlab.uni-muenster.de/m_kueh11/fp-dm-tool (Accessed: 10 July 2024).<br><br>\n",
    "**[3]** Sandfort, F. et al. (2020) ‘A structure-based platform for predicting chemical reactivity’, *Chem*, 6(6), pp. 1379–1390.<br><br>\n",
    "**[4]** Ahneman, D.T. et al. (2018) ‘Predicting reaction performance in C–N cross-coupling using machine learning’, *Science*, 360(6385), pp. 186–190.<br><br>\n",
    "**[5]** Sigman, M.S., Harper, K.C., Bess, E.N., and Milo, A. (2016) 'The development of multidimensional analysis tools for asymmetric catalysis and beyond', *Acc. Chem. Res.*, 49,\n",
    "pp 1292–1301.<br><br>\n",
    "**[6]**  Denmark, S.E., Gould, N.D., and Wolf, L.M. (2011). A systematic investigation of quaternary ammonium ions as asymmetric phase-transfer catalysts. Application of quantitative structure activity/selectivity relationships. *J. Org. Chem.*,76, pp 4337–4357.<br><br>\n",
    "**[7]** Zahrt, A.F. et al. (2019) ‘Prediction of higher-selectivity catalysts by computer-driven workflow and machine learning’, *Science*, 363(6424).<br><br>\n",
    "**[8]** G. K. Ingle, M. G. Mormino, L. Wojtas, J. C. Antilla, Chiral phosphoric acid-catalyzed addition of thiols to N-acyl imines: Access to chiral N,S-acetals. *Org. Lett.* 13, 4822–4825 (2011)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
